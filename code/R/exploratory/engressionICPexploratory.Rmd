---
title: "engression_worksheet"
author: "Philip Boustani"
date: "2024-03-24"
output: html_document
---

# Setup Rmarkdown

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# install and loed packages

```{r}
# List of required packages
packages <- c(
  "engression",
  "CondIndTests", 
  "lawstat", # For levene.test
  "stats", # For ks.test, wilcox.test
  "mgcv", # for fitting GAMs
  "nonlinearICP",
  "readtext", # loading csv files
  # "utils", # progress bar 
  "foreach",
  "doSNOW"  # parallel processing with progress bar 
            # otherwise "doParallel" is an option for parallel processing
)

# First, installing packages which are not yet installed and then loading all of them
load_packages <- function(packages){
  for (pkg in packages) {
    if(!require(pkg, character.only = TRUE)){
      install.packages(pkg, character.only = TRUE);
      library(pkg, character.only = TRUE)
    }
  }
}

# loading packages
load_packages(packages)
```

# load all required source files

```{r}
# List of required source files
files <- c(
)

# if applicable, specify entire folders to be loaded
folders <- c(
  "engression_supplementary",
  "external_modified"
)

# Detect working directory and load all files 
load_files <- function(files, folders, directory){
  
  paths <- c(
    file.path(directory, files),
    file.path(directory, list.files(folders, full.names = TRUE))
  )
  
  for (path in paths) {
    source(path)
  }
}

# loading directory  
directory <- getwd()
load_files(files, folders, directory)
```

# ---------------------------------------------------------------------------- #
# Archive for old Code 

```{r}
n <- 100 # \in (100, 200, 500, 2000, 5000)
SimRep <- 100
pb <- txtProgressBar(min = 0, max = SimRep, style = 3)
method <- "engression"

for (Sim in 1:SimRep){
  # cat(round(Sim/SimRep*100),"% is simulated. \n")
  setTxtProgressBar(pb, Sim)

  tryCatch({

  Simulation <- gen_sample(n = n, d = d, dag = dag,
                  signs = dag_signs, target = "random",
                  verbose = FALSE )

  target <- Simulation$statistics[2]
  S_sets <- obtain_S(target, d)
  pvals <- rep(NA, length(S_sets))
  names(pvals) <- paste("pvSet",1:length(S_sets),sep = "_")

  for (k in 1:length(S_sets)) {

    S_k <- S_sets[[k]]

    pvals[k] <- InvResDisTest(
      Y = Simulation$sample[,target], E = as.factor(Simulation$sample[,"E"]),
      X = Simulation$sample[,S_k],
      alpha = 0.05,
      verbose = FALSE, fitmodel = method,
      test = leveneAndWilcoxResidualDistributions, colNameNoSmooth = NULL,
      mtry = sqrt(NCOL(X)), ntree = 100, nodesize = 5, maxnodes = NULL,
      noise_dim = 5,
      hidden_dim = 100,
      num_layer = 3,
      num_epochs = 30, # default set to 1000
      silent = TRUE,
      returnModel = FALSE
    )$pvalue
  }

  record_stats( c(Simulation$statistics,
                  round(pvals,4)),
               title = paste("SimulationReport", method, sep = "_") )
  record_stats(Simulation$documentation,
               title = paste("InterventionDocumentation", method, sep = "_") )

  }, error = function(e) {
    record_stats( c(Simulation$statistics,
                  conditionMessage(e)),
               title =  paste("ErrorReport", method, sep = "_") )
  }
  )
}
close(pb)
```


```{r}
S_sets <- obtain_S(target, d)
pvals <- rep(NA, length(S_sets))

for (k in 1:length(S_sets)) {
  cat(round(k/length(S_sets)*100),"% : Computing set", k, "out of", length(S_sets), "\n")
  
  S_k <- S_sets[[k]]
  
  pvals[k] <- InvResDisTest(
    Y = Simulation$sample[,target], E = as.factor(Simulation$sample[,"E"]), 
    X = Simulation$sample[,S_k], 
    alpha = 0.05,
    verbose = FALSE, fitmodel = "GAM",
    test = leveneAndWilcoxResidualDistributions, colNameNoSmooth = NULL,
    mtry = sqrt(NCOL(X)), ntree = 100, nodesize = 5, maxnodes = NULL,
    noise_dim = 5,
    hidden_dim = 100,
    num_layer = 3,
    num_epochs = 30, # default set to 1000
    silent = TRUE, 
    returnModel = FALSE
  )$pvalue
}

accepted_sets <- get_accepted(pvals, S_sets)
# compute defining sets
defining_set <- get_defining(accepted_sets, S_sets)
defSet_dummy <- grepl(paste(defining_set, collapse = "|"), paste("Z", 1:d, sep = "_"))
if (length(defining_set) == 0)  defSet_dummy <- rep(FALSE, d)
names(defSet_dummy) <- paste("defSet", 1:6, sep = "_")

# compute intersection sets
intersection_set <- get_intersection(accepted_sets)
intSet_dummy <- grepl(paste(intersection_set, collapse = "|"), paste("Z", 1:d, sep = "_"))
if (length(intersection_set) == 0)  intSet_dummy <- rep(FALSE, d)
names(intSet_dummy) <- paste("intSet", 1:6, sep = "_")


union_set <- get_union(accepted_sets); cat("union_set =", union_set, "\n") 
defining_set <- get_defining(accepted_sets, S_sets); cat("defining_set: \n")
defining_set
intersection_set <- get_intersection(accepted_sets); cat("intersection_set =", intersection_set, "\n")
```





```{r}
X <- Simulation$sample[, !(colnames(Simulation$sample) %in% c(target, "E"))] 

setss <- nonlinearICP(X = X, 
                      Y = Simulation$sample[,target], 
                      environment = as.factor(Simulation$sample[,"E"]),
             condIndTest = InvariantResidualDistributionTest,
             argsCondIndTest = NULL,
             alpha=0.05,
             varPreSelectionFunc = NULL,
             argsVarPreSelectionFunc = NULL,
             maxSizeSets = ncol(X),
             condIndTestNames = NULL,
             speedUp = FALSE,
             subsampleSize = c(0.1, 0.25, 0.5, 0.75, 1),
             retrieveDefiningsSets = TRUE,
             seed = 1,
             stopIfEmpty = TRUE,
             testAdditionalSet = NULL,
             verbose = FALSE)

setss$retrievedCausalVars
setss$acceptedSets
setss$definingSets
# increment_nodes(target, as.vector(setss$definingSets[[1]]))
summary(setss)
```

```{r}
increment_nodes <- function(target, var_list) {
  # Extract the node number from the target
  node <- as.numeric(gsub("\\D", "", target))
  
  # Increment numbers in var_list if they are equal to or larger than node
  result <- sapply(var_list, function(x) {
    if (is.numeric(x)) {
      if (x >= node) {
        return(paste0("Z_", x + 1))
      } else {
        return(paste0("Z_", x))
      }
    } else {
      return(x)
    }
  })
  
  return(result)
}
```


```{r}
# Fit GAM and Engression on simulated data
Y <- Sim$sample[,target]
X <- Sim$sample[,defining_set]
E <- Sim$sample[,"E"]
  
gamfit <- gam(Y ~ s(X))
Yhat_gam <- gamfit$fitted.values

engfit <- engression(
    X,
    Y,
    noise_dim = 5,
    hidden_dim = 100,
    num_layer = 3,
    dropout = 0.05,
    batch_norm = TRUE,
    num_epochs = 50,
    lr = 10^(-3),
    beta = 1,
    silent = TRUE,
    standardize = TRUE
)

Yhat_eng <- predict(engfit, X)
```


```{r}
# Plot the Fits
regressor <- "Z_2"
plot(x = Sim$sample[,regressor], y = Sim$sample[,target], type = 'n')

points(Sim$sample[,regressor], Sim$sample[,target],
       col = rgb(Sim$sample[,"E"]==1, Sim$sample[,"E"]==2, Sim$sample[,"E"]==3, alpha = 0.4), pch = 16)
points(Sim$sample[,regressor],Yhat_gam)
points(Sim$sample[,regressor],Yhat_eng, pch = "+")
```


```{r}
# Compute Kolmogorov-Smirnov test
gamres <- Yhat_gam - Y
engres <- Yhat_eng - Y
ks.test(gamres[E==1],gamres[E!=1])
ks.test(engres[E==1],engres[E!=1])
```



```{r}
computeDefiningSets <- function(as){

  if(length(as) == 0) return(list())

  treeList <- list()

  # add all singletons
  indSingletons <- which(sapply(as, length) == 1)
  singletons <- as[indSingletons]

  if(length(singletons) > 0){
    for(i in 1:length(singletons)){
      if(i == 1) treeList[[1]] <- Node$new(singletons[1])
      else{
        addTo <- Traverse(treeList[[1]], filterFun = isLeaf)
        addTo[[1]]$AddChild(singletons[i])
      }

      ind <- which(sapply(as, function(x) is.element(unlist(singletons[i]), x)))
      if(length(ind) > 0) as <- as[-ind]
    }

  }

  # create root node of tree(s)
  if(length(as) > 0){
    occur <- table(unlist(as))
    uniqueVars <- sort(unique(unlist(as)))

    if(length(treeList) == 0){
      for(i in 1:length(uniqueVars)){
        treeList[[length(treeList) + 1]] <- Node$new(uniqueVars[i])
      }
    }else{

      for(tl in 1:length(treeList)){
        leafNode <- Traverse(treeList[[tl]], filterFun = isLeaf)

        for(i in 1:length(uniqueVars)){
          leafNode[[1]]$AddChild(uniqueVars[i])
        }
      }
    }

    # grow trees
    for(i in 1:length(treeList)){

      cont <- TRUE

      while(cont){

        leafNodes <- Traverse(treeList[[i]], filterFun = isLeaf)
        leafNodePath <- lapply(leafNodes, function(i) i$path)
        continueAny <- rep(TRUE, times = length(leafNodePath))

        for(ln in 1:length(leafNodes)){
          # remove sets with variables already in branch
          toRemove <- as.numeric(leafNodePath[[ln]]) # leave node + path to root
          addTo <- leafNodes[[ln]]

          ind <- NULL
          for(elem in 1:length(toRemove)){
            ind <- c(ind, which(sapply(as, function(x) is.element(toRemove[elem], x))))
          }

          asReduced <- if(length(ind) > 0) as[-ind] else as

          if(length(asReduced) == 0){
            continueAny[ln] <- FALSE
          }else{
            # get subtree
            treeList[[i]] <- buildTrees(asReduced, treeList[[i]], addTo)
          }

        }
        cont <- any(continueAny)
      }

    }
  }

  # prune
  sets <- NULL
  for(i in 1:length(treeList)){
    x <- ToDataFrameTree(treeList[[i]], "pathString", "isLeaf")

    idxLeaves <- which(x$isLeaf)
    sets <- c(sets, lapply(x[idxLeaves, "pathString"],
                   function(x) sort(as.numeric(strsplit(x, "/")[[1]]))))
  }

  idxNotDup <- which(!duplicated(sets))
  setsUnique <- sets[idxNotDup]

  isSubset <- function(set1, set2){
    all(sapply(set1, function(el) is.element(el, set2)))
  }

  lengthSetsUnique <- sapply(setsUnique, length)
  idxMinSets <- which(lengthSetsUnique == min(lengthSetsUnique))

  remove <- NULL
  for(mS in 1:length(idxMinSets)){
    remove <- c(remove, which(sapply(setsUnique, function(sU) isSubset(setsUnique[idxMinSets[mS]], sU))))
  }

  remove <- setdiff(remove, idxMinSets)
  setsUnique <- if(length(remove) > 0) setsUnique[-remove] else setsUnique

  lengthsSets <- sapply(setsUnique, length)
  setsUnique[order(lengthsSets)]
}
```

```{r}
packages <- c(
  "methods",
    "randomForest",
    "quantregForest",
    "lawstat",
    "RPtests",
    "caTools",
    "mgcv",
    "MASS",
    "kernlab",
    "pracma", 
    "mize"
)

# First, installing packages which are not yet installed and then loading all of them
load_packages <- function(packages){
  for (pkg in packages) {
    if(!require(pkg, character.only = TRUE)){
      install.packages(pkg, character.only = TRUE);
      library(pkg, character.only = TRUE)
    }
  }
}

# loading packages
load_packages(packages)
```

```{r}
library("data.tree")
```


```{r}
computeDefiningSets(setss$acceptedSets)
```

```{r}
computeDefiningSets(numeric_sets)
```



```{r}
# Initialize a list to store the modified sets
numeric_sets <- vector("list", length = length(accepted_sets))

# Loop through each entry in accepted_sets
for (i in seq_along(accepted_sets)) {
  # Remove "Z_" from each element in the current set and convert to numeric
  numeric_sets[[i]] <- as.numeric(sub("Z_", "", accepted_sets[[i]]))
}

# Print the resulting numeric sets
numeric_sets

```

