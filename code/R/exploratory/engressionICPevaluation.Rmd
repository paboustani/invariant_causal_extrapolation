---
title: "engression_worksheet"
author: "Philip Boustani"
date: "2024-03-24"
output: html_document
---

# Setup Rmarkdown

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# install and loed packages

```{r}
# List of required packages
packages <- c(
  "engression",
  "CondIndTests", 
  "lawstat", # For levene.test
  "stats", # For ks.test, wilcox.test
  "mgcv", # for fitting GAMs
  "nonlinearICP",
  "readtext", # loading csv files
  # "utils", # progress bar 
  "foreach",
  "doSNOW",  # parallel processing with progress bar 
  "data.tree" # to create tree structures from hierarchical data
)

# First, installing packages which are not yet installed and then loading all of them
load_packages <- function(packages){
  for (pkg in packages) {
    if(!require(pkg, character.only = TRUE)){
      install.packages(pkg, character.only = TRUE);
      library(pkg, character.only = TRUE)
    }
  }
}

# loading packages
load_packages(packages)
```

# load all required source files

```{r}
# List of required source files
files <- c(
)

# if applicable, specify entire folders to be loaded
folders <- c(
  "engression_supplementary",
  "external_modified"
)

# Detect working directory and load all files 
load_files <- function(files, folders, directory){
  
  paths <- c(
    file.path(directory, files),
    file.path(directory, list.files(folders, full.names = TRUE))
  )
  
  for (path in paths) {
    source(path)
  }
}

# loading directory  
directory <- getwd()
load_files(files, folders, directory)
```

# ---------------------------------------------------------------------------- #
# Archive for old Code 

```{r}
n <- 100 # \in (100, 200, 500, 2000, 5000)
SimRep <- 100
pb <- txtProgressBar(min = 0, max = SimRep, style = 3)
method <- "engression"

for (Sim in 1:SimRep){
  # cat(round(Sim/SimRep*100),"% is simulated. \n")
  setTxtProgressBar(pb, Sim)

  tryCatch({

  Simulation <- gen_sample(n = n, d = d, dag = dag,
                  signs = dag_signs, target = "random",
                  verbose = FALSE )

  target <- Simulation$statistics[2]
  S_sets <- obtain_S(target, d)
  pvals <- rep(NA, length(S_sets))
  names(pvals) <- paste("pvSet",1:length(S_sets),sep = "_")

  for (k in 1:length(S_sets)) {

    S_k <- S_sets[[k]]

    pvals[k] <- InvResDisTest(
      Y = Simulation$sample[,target], E = as.factor(Simulation$sample[,"E"]),
      X = Simulation$sample[,S_k],
      alpha = 0.05,
      verbose = FALSE, fitmodel = method,
      test = leveneAndWilcoxResidualDistributions, colNameNoSmooth = NULL,
      mtry = sqrt(NCOL(X)), ntree = 100, nodesize = 5, maxnodes = NULL,
      noise_dim = 5,
      hidden_dim = 100,
      num_layer = 3,
      num_epochs = 30, # default set to 1000
      silent = TRUE,
      returnModel = FALSE
    )$pvalue
  }

  record_stats( c(Simulation$statistics,
                  round(pvals,4)),
               title = paste("SimulationReport", method, sep = "_") )
  record_stats(Simulation$documentation,
               title = paste("InterventionDocumentation", method, sep = "_") )

  }, error = function(e) {
    record_stats( c(Simulation$statistics,
                  conditionMessage(e)),
               title =  paste("ErrorReport", method, sep = "_") )
  }
  )
}
close(pb)
```


```{r}
S_sets <- obtain_S(target, d)
pvals <- rep(NA, length(S_sets))

for (k in 1:length(S_sets)) {
  cat(round(k/length(S_sets)*100),"% : Computing set", k, "out of", length(S_sets), "\n")
  
  S_k <- S_sets[[k]]
  
  pvals[k] <- InvResDisTest(
    Y = Simulation$sample[,target], E = as.factor(Simulation$sample[,"E"]), 
    X = Simulation$sample[,S_k], 
    alpha = 0.05,
    verbose = FALSE, fitmodel = "GAM",
    test = leveneAndWilcoxResidualDistributions, colNameNoSmooth = NULL,
    mtry = sqrt(NCOL(X)), ntree = 100, nodesize = 5, maxnodes = NULL,
    noise_dim = 5,
    hidden_dim = 100,
    num_layer = 3,
    num_epochs = 30, # default set to 1000
    silent = TRUE, 
    returnModel = FALSE
  )$pvalue
}

accepted_sets <- get_accepted(pvals, S_sets)
# compute defining sets
defining_set <- get_defining(accepted_sets, S_sets)
defSet_dummy <- grepl(paste(defining_set, collapse = "|"), paste("Z", 1:d, sep = "_"))
if (length(defining_set) == 0)  defSet_dummy <- rep(FALSE, d)
names(defSet_dummy) <- paste("defSet", 1:6, sep = "_")

# compute intersection sets
intersection_set <- get_intersection(accepted_sets)
intSet_dummy <- grepl(paste(intersection_set, collapse = "|"), paste("Z", 1:d, sep = "_"))
if (length(intersection_set) == 0)  intSet_dummy <- rep(FALSE, d)
names(intSet_dummy) <- paste("intSet", 1:6, sep = "_")


union_set <- get_union(accepted_sets); cat("union_set =", union_set, "\n") 
defining_set <- get_defining(accepted_sets, S_sets); cat("defining_set: \n")
defining_set
intersection_set <- get_intersection(accepted_sets); cat("intersection_set =", intersection_set, "\n")
```





```{r}
X <- Simulation$sample[, !(colnames(Simulation$sample) %in% c(target, "E"))] 

setss <- nonlinearICP(X = X, 
                      Y = Simulation$sample[,target], 
                      environment = as.factor(Simulation$sample[,"E"]),
             condIndTest = InvariantResidualDistributionTest,
             argsCondIndTest = NULL,
             alpha=0.05,
             varPreSelectionFunc = NULL,
             argsVarPreSelectionFunc = NULL,
             maxSizeSets = ncol(X),
             condIndTestNames = NULL,
             speedUp = FALSE,
             subsampleSize = c(0.1, 0.25, 0.5, 0.75, 1),
             retrieveDefiningsSets = TRUE,
             seed = 1,
             stopIfEmpty = TRUE,
             testAdditionalSet = NULL,
             verbose = FALSE)

setss$retrievedCausalVars
setss$acceptedSets
setss$definingSets
# increment_nodes(target, as.vector(setss$definingSets[[1]]))
summary(setss)
```

```{r}
increment_nodes <- function(target, var_list) {
  # Extract the node number from the target
  node <- as.numeric(gsub("\\D", "", target))
  
  # Increment numbers in var_list if they are equal to or larger than node
  result <- sapply(var_list, function(x) {
    if (is.numeric(x)) {
      if (x >= node) {
        return(paste0("Z_", x + 1))
      } else {
        return(paste0("Z_", x))
      }
    } else {
      return(x)
    }
  })
  
  return(result)
}
```


```{r}
# Fit GAM and Engression on simulated data
Y <- Sim$sample[,target]
X <- Sim$sample[,defining_set]
E <- Sim$sample[,"E"]
  
gamfit <- gam(Y ~ s(X))
Yhat_gam <- gamfit$fitted.values

engfit <- engression(
    X,
    Y,
    noise_dim = 5,
    hidden_dim = 100,
    num_layer = 3,
    dropout = 0.05,
    batch_norm = TRUE,
    num_epochs = 50,
    lr = 10^(-3),
    beta = 1,
    silent = TRUE,
    standardize = TRUE
)

Yhat_eng <- predict(engfit, X)
```


```{r}
# Plot the Fits
regressor <- "Z_2"
plot(x = Sim$sample[,regressor], y = Sim$sample[,target], type = 'n')

points(Sim$sample[,regressor], Sim$sample[,target],
       col = rgb(Sim$sample[,"E"]==1, Sim$sample[,"E"]==2, Sim$sample[,"E"]==3, alpha = 0.4), pch = 16)
points(Sim$sample[,regressor],Yhat_gam)
points(Sim$sample[,regressor],Yhat_eng, pch = "+")
```


# Comput Jaccard similarity

```{r}
convertSetToNumeric <- function(accepted_sets){
  # Initialize a list to store the modified sets
  numeric_sets <- list()
  
  # Loop through each entry in accepted_sets
  for (i in seq_along(accepted_sets)) {
    # Remove "Z_" from each element in the current set and convert to numeric
    numeric_sets[[i]] <- as.numeric(sub("Z_", "", accepted_sets[[i]]))
  }
  
  return(numeric_sets)
}

convertSetToCharacter <- function(numeric_sets){
  # Initialize a list to store the modified sets
  set_sets <- list()
  
  # Loop through each entry in numeric_sets
  for (i in seq_along(numeric_sets)) {
    # Add "Z_" to each element in the current numeric set and convert to character
    set_sets[[i]] <- paste0("Z_", as.character(numeric_sets[[i]]))
  }
  return(set_sets)
}

is_subset <- function(sets, parents){
  isSubsets <- sapply(def_set, function(x) 
    if (length(x) == 0) {return(FALSE)} else {
    all(x %in% unlist(parents)) } )
  return(isSubsets)
}
```


```{r}
directory <- getwd()
method <- "GAM"
title <- paste("SimulationReport", method, sep = "_")
impdir = directory
fileform = "csv"
delim = ";"
filename <- paste(impdir, "/", title, ".", fileform, sep = "")
statistics <- read.csv(filename, header = TRUE, sep = delim, encoding="UTF-8")
pvals <- statistics[ , grepl("pvSet_" , names( statistics ) ) ]

nvec <- dim(pvals)[1]
AbsIntSetVec <- numeric(nvec)
AbsUnSetVec <- numeric(nvec)
sInParents <- numeric(nvec)
intInParents <- numeric(nvec)

for (Sim in 1:nvec) {
  target <- statistics[Sim,"target"]
  S_sets <- obtain_S(target, d)
  parents <- get_parents(target,dag = dag)
  
  accepted_sets <- get_accepted(pvals[Sim,], S_sets)
  accepted_sets <- convertSetToNumeric(accepted_sets)
  parents_no <- convertSetToNumeric(list(parents))
    
  def_set <- computeDefiningSets(accepted_sets)
  int_set <- computeSetIntersection(accepted_sets)
  
  AppndSets <- append(parents_no, def_set)
  AbsIntSetVec[Sim] <- length( computeSetIntersection(AppndSets) )
  AbsUnSetVec[Sim] <- length( get_union(AppndSets) )
  
  allSub <- is_subset(def_set,parents_no)
  if (length(allSub)==0) allSub <- 0 
  sInParents[Sim] <- sum(allSub) == length(def_set)
  
  allSub <- is_subset(int_set,parents_no)
  if (length(allSub)==0) allSub <- 0 
  intInParents[Sim] <- sum(allSub) == length(int_set)
}

Jaccard <- AbsIntSetVec/ AbsUnSetVec
statistics <- cbind(statistics, 
                    "AbsIntSetVec" = AbsIntSetVec, 
                    "AbsUnSetVec" = AbsUnSetVec, 
                    "Jaccard" = Jaccard)
mean(Jaccard, na.rm = TRUE)
mean(1-intInParents)
```


# Generating Extrapolation sample 


```{r}
n <- 1000
E <- 2
target <- "Z_3"
shift <- sample(c(TRUE, FALSE),1)
  
Simulation <- sim_data(n, d, dag = dag, coeff_signs = dag_signs, 
         target =  "Z_3", 
         eta_df = 2, # $\in \{2, 3, 5, 10, 20, 50, 100\}
         f_id = 1, # $\in \{1, 2, 3, 4\}
         multiplic = "product", # $\in \{"product", "sum"\}
         E = 1, # $\in \{1, 2, 3\}$
         shift = TRUE, # $\in \{TRUE, FALSE\}$
         interv = "all", # $\in \{"all", "rand", "close"\}$
         epsilon_df = 2, # $\in \{2, 3, 5, 10, 20, 50, 100\}$
         meanshift = 0.1, # $\in \{0, 0.1, 0.2, 0.5, 1, 2, 5, 10\}
         strength = 0.1, # $\in \{0, 0.1, 0.2, 0.5, 1, 2, 5, 10\} 
         verbose = FALSE)

data <- as.data.frame(Simulation$sample)
  
perc40 <- quantile(data$Z_1, 0.4)
data$test <- as.numeric(data$"Z_1" > perc40)

trainData <- data[data$test==0,]
testData <- data[data$test==1,]


Zvars <- grep("^Z_", names(data), value = TRUE)
Xvars <- Zvars[!Zvars %in% c(target)]

engFit <- engression(
  X = trainData[,Xvars],
  Y = trainData[,target],
  noise_dim = 5,
  hidden_dim = 100,
  num_layer = 3,
  dropout = 0.05,
  batch_norm = TRUE,
  num_epochs = 50,
  lr = 10^(-3),
  beta = 1,
  silent = TRUE,
  standardize = TRUE
)


Yhat_eng <- predict(engFit, testData[,Xvars])

form <- as.formula( paste( "Y ~ ", paste( "s(", Xvars,")",collapse=" + "),sep=""))
gamFit <- gam(form, data = trainData)



# mahalanobis(x = data[2,], center = data[1,], cov = cov(data))
```










```{r}
plot(x = data$Z_4, y = data$Z_3, 
     col = rgb(data$test==1, (1-data$test)==2, 0, alpha = 0.4), 
     pch = 16)

```

